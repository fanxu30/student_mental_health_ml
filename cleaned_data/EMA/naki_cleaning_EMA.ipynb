{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Path\n",
    "folderExercise = \"./../../raw_data/EMA/response/Exercise/\"\n",
    "\n",
    "# List to collect all rows\n",
    "all_rows = []\n",
    "\n",
    "# Loop through all files in the Exercise folder\n",
    "for filename in os.listdir(folderExercise):\n",
    "    if filename.startswith(\"Exercise_u\") and filename.endswith(\".json\"):\n",
    "        user_id = filename.replace(\"Exercise_\", \"\").replace(\".json\", \"\")\n",
    "        file_path = os.path.join(folderExercise, filename)\n",
    "        # print(f\"Processing file: {filename}\")\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            try:\n",
    "                entries = json.load(f)\n",
    "            except Exception as e:\n",
    "                # print(f\"Failed to load {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "        for entry in entries:\n",
    "            # Parse values with fallbacks\n",
    "            exercise = entry.get(\"exercise\")\n",
    "            walk = entry.get(\"walk\")\n",
    "            have = entry.get(\"have\")\n",
    "            schedule = entry.get(\"schedule\")\n",
    "            location = entry.get(\"location\", None)\n",
    "            resp_time = entry.get(\"resp_time\", None)\n",
    "\n",
    "            # Convert timestamp to datetime\n",
    "            if resp_time:\n",
    "                dt = datetime.fromtimestamp(resp_time, tz=timezone.utc)\n",
    "\n",
    "                readable_time = dt.isoformat()\n",
    "                weekday = dt.strftime(\"%A\")\n",
    "                hour = dt.hour\n",
    "            else:\n",
    "                readable_time = None\n",
    "                weekday = None\n",
    "                hour = None\n",
    "\n",
    "            # Handle location\n",
    "            lat, lon = None, None\n",
    "            if location and location != \"Unknown\" and location != \"null\":\n",
    "                try:\n",
    "                    lat_str, lon_str = location.split(\",\")\n",
    "                    lat, lon = float(lat_str), float(lon_str)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            row = {\n",
    "                \"user_id\": user_id,\n",
    "                \"resp_time\": readable_time,\n",
    "                \"weekday\": weekday,\n",
    "                \"hour\": hour,\n",
    "                \"exercise\": int(exercise) if exercise and exercise != \"null\" else None,\n",
    "                \"walk\": int(walk) if walk and walk != \"null\" else None,\n",
    "                \"have\": int(have) if have and have != \"null\" else None,\n",
    "                \"schedule\": int(schedule) if schedule and schedule != \"null\" else None,\n",
    "                \"latitude\": lat,\n",
    "                \"longitude\": lon,\n",
    "                \"has_location\": int(location not in [\"Unknown\", \"null\", None]),\n",
    "            }\n",
    "\n",
    "            all_rows.append(row)\n",
    "\n",
    "# Create a DataFrame\n",
    "df_exercise = pd.DataFrame(all_rows)\n",
    "df_exercise = df_exercise.sort_values(\n",
    "    by=[\"user_id\", \"resp_time\"]\n",
    ")  # sort by user + time\n",
    "\n",
    "# Save to CSV\n",
    "# df_exercise.to_csv(\"./Exercise.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing Social_u00.json to Social_u59.json\n",
    "folderExercise = \"./../../raw_data/EMA/response/Social/\"\n",
    "\n",
    "# Store cleaned entries\n",
    "all_social_data = []\n",
    "\n",
    "# Loop through all relevant files\n",
    "for filename in os.listdir(folderExercise):\n",
    "    if filename.startswith(\"Social_u\") and filename.endswith(\".json\"):\n",
    "        user_id = filename.replace(\"Social_\", \"\").replace(\".json\", \"\")\n",
    "        file_path = os.path.join(folderExercise, filename)\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            try:\n",
    "                entries = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "        for entry in entries:\n",
    "            number = entry.get(\"number\")\n",
    "            location = entry.get(\"location\")\n",
    "            resp_time = entry.get(\"resp_time\")\n",
    "\n",
    "            # Convert timestamp to UTC datetime\n",
    "            try:\n",
    "                dt = datetime.fromtimestamp(resp_time, tz=timezone.utc)\n",
    "            except:\n",
    "                dt = None\n",
    "\n",
    "            all_social_data.append(\n",
    "                {\n",
    "                    \"user_id\": user_id,\n",
    "                    \"resp_time\": resp_time,\n",
    "                    \"datetime_utc\": dt,\n",
    "                    \"number\": number,\n",
    "                    \"location\": location,\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_social = pd.DataFrame(all_social_data)\n",
    "df_social = df_social.sort_values(by=[\"user_id\", \"datetime_utc\"])  # sort by user + time\n",
    "\n",
    "# Save to CSV\n",
    "# df_social.to_csv(\"./Social.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where Sleep_uXX.json files are located\n",
    "folderSleep = \"./../../raw_data/EMA/response/Sleep/\"\n",
    "\n",
    "# Collect cleaned records\n",
    "all_sleep_data = []\n",
    "\n",
    "# Go through all Sleep_uXX.json files\n",
    "for filename in os.listdir(folderSleep):\n",
    "    if filename.startswith(\"Sleep_u\") and filename.endswith(\".json\"):\n",
    "        user_id = filename.replace(\"Sleep_\", \"\").replace(\".json\", \"\")\n",
    "        file_path = os.path.join(folderSleep, filename)\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            try:\n",
    "                entries = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "        for entry in entries:\n",
    "            sleep_hours = entry.get(\"hour\")\n",
    "            sleep_quality = entry.get(\"rate\")\n",
    "            sleepiness = entry.get(\"social\")  # Trouble staying awake\n",
    "            location = entry.get(\"location\")\n",
    "            resp_time = entry.get(\"resp_time\")\n",
    "\n",
    "            # Convert timestamp to UTC datetime\n",
    "            try:\n",
    "                dt = datetime.fromtimestamp(resp_time, tz=timezone.utc)\n",
    "            except:\n",
    "                dt = None\n",
    "\n",
    "            all_sleep_data.append(\n",
    "                {\n",
    "                    \"user_id\": user_id,\n",
    "                    \"resp_time\": resp_time,\n",
    "                    \"datetime_utc\": dt,\n",
    "                    \"sleep_hours\": sleep_hours,\n",
    "                    \"sleep_quality\": sleep_quality,\n",
    "                    \"sleepiness\": sleepiness,\n",
    "                    \"location\": location,\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_sleep = pd.DataFrame(all_sleep_data)\n",
    "df_sleep = df_sleep.sort_values(by=[\"user_id\", \"datetime_utc\"])  # sort by user + time\n",
    "\n",
    "# df_sleep.to_csv(\"./Sleep.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing Event_uXX.json files\n",
    "folderEvents = \"./../../raw_data/EMA/response/Events/\"\n",
    "\n",
    "all_event_data = []\n",
    "\n",
    "for filename in os.listdir(folderEvents):\n",
    "    if filename.startswith(\"Events_u\") and filename.endswith(\".json\"):\n",
    "        user_id = filename.replace(\"Events_\", \"\").replace(\".json\", \"\")\n",
    "        filepath = os.path.join(folderEvents, filename)\n",
    "\n",
    "        with open(filepath, \"r\") as f:\n",
    "            try:\n",
    "                records = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not read {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "        for r in records:\n",
    "            # Convert timestamp\n",
    "            try:\n",
    "                dt = datetime.fromtimestamp(r.get(\"resp_time\"), tz=timezone.utc)\n",
    "            except:\n",
    "                dt = None\n",
    "\n",
    "            all_event_data.append(\n",
    "                {\n",
    "                    \"user_id\": user_id,\n",
    "                    \"resp_time\": r.get(\"resp_time\"),\n",
    "                    \"datetime_utc\": dt,\n",
    "                    \"positive_event_score\": (\n",
    "                        int(r[\"positive\"])\n",
    "                        if r.get(\"positive\") not in [None, \"null\"]\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"negative_event_score\": (\n",
    "                        int(r[\"negative\"])\n",
    "                        if r.get(\"negative\") not in [None, \"null\"]\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"emotion_range\": (\n",
    "                        int(r[\"positive\"]) - int(r[\"negative\"])\n",
    "                        if r.get(\"positive\")\n",
    "                        and r.get(\"negative\")\n",
    "                        and r[\"positive\"] != \"null\"\n",
    "                        and r[\"negative\"] != \"null\"\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"has_positive_text\": 1 if r.get(\"pevent\") else 0,\n",
    "                    \"has_negative_text\": 1 if r.get(\"nevent\") else 0,\n",
    "                    \"positive_text\": r.get(\"pevent\"),\n",
    "                    \"negative_text\": r.get(\"nevent\"),\n",
    "                    \"location\": r.get(\"location\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Create DataFrame and save\n",
    "df_event = pd.DataFrame(all_event_data)\n",
    "# df_event.to_csv(\"./Events.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing Class2_uXX.json files\n",
    "folderClass = \"./../../raw_data/EMA/response/Class 2/\"\n",
    "all_class_data = []\n",
    "\n",
    "for filename in os.listdir(folderClass):\n",
    "    if filename.startswith(\"Class 2_u\") and filename.endswith(\".json\"):\n",
    "        user_id = filename.replace(\"Class 2_\", \"\").replace(\".json\", \"\")\n",
    "        filepath = os.path.join(folderClass, filename)\n",
    "\n",
    "        with open(filepath, \"r\") as f:\n",
    "            try:\n",
    "                records = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not read {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "        for r in records:\n",
    "            # Convert timestamp if exists\n",
    "            try:\n",
    "                dt = datetime.fromtimestamp(r.get(\"resp_time\"), tz=timezone.utc)\n",
    "            except:\n",
    "                dt = None\n",
    "\n",
    "            all_class_data.append(\n",
    "                {\n",
    "                    \"user_id\": user_id,\n",
    "                    \"resp_time\": r.get(\"resp_time\"),\n",
    "                    \"datetime_utc\": dt,\n",
    "                    \"challenge\": r.get(\"challenge\"),\n",
    "                    \"effort\": r.get(\"effort\"),\n",
    "                    \"grade\": r.get(\"grade\"),\n",
    "                    \"location\": r.get(\"location\"),  # Assuming it's a string or missing\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Create DataFrame and save\n",
    "df_class = pd.DataFrame(all_class_data)\n",
    "df_class.to_csv(\"./Class2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
