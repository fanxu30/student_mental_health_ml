{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Path\n",
    "folderExercise = \"./raw_data/EMA/response/Exercise/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Exercise_u00.json\n",
      "Processing file: Exercise_u57.json\n",
      "Processing file: Exercise_u41.json\n",
      "Processing file: Exercise_u16.json\n",
      "Processing file: Exercise_u36.json\n",
      "Processing file: Exercise_u20.json\n",
      "Processing file: Exercise_u17.json\n",
      "Processing file: Exercise_u56.json\n",
      "Processing file: Exercise_u01.json\n",
      "Processing file: Exercise_u30.json\n",
      "Processing file: Exercise_u51.json\n",
      "Processing file: Exercise_u47.json\n",
      "Processing file: Exercise_u10.json\n",
      "Processing file: Exercise_u46.json\n",
      "Processing file: Exercise_u50.json\n",
      "Processing file: Exercise_u07.json\n",
      "Processing file: Exercise_u27.json\n",
      "Processing file: Exercise_u31.json\n",
      "Processing file: Exercise_u49.json\n",
      "Processing file: Exercise_u08.json\n",
      "Processing file: Exercise_u24.json\n",
      "Processing file: Exercise_u32.json\n",
      "Processing file: Exercise_u12.json\n",
      "Processing file: Exercise_u45.json\n",
      "Processing file: Exercise_u53.json\n",
      "Processing file: Exercise_u04.json\n",
      "Processing file: Exercise_u05.json\n",
      "Processing file: Exercise_u52.json\n",
      "Processing file: Exercise_u44.json\n",
      "Processing file: Exercise_u13.json\n",
      "Processing file: Exercise_u33.json\n",
      "Processing file: Exercise_u25.json\n",
      "Processing file: Exercise_u09.json\n",
      "Processing file: Exercise_u14.json\n",
      "Processing file: Exercise_u43.json\n",
      "Processing file: Exercise_u02.json\n",
      "Processing file: Exercise_u18.json\n",
      "Processing file: Exercise_u59.json\n",
      "Processing file: Exercise_u22.json\n",
      "Processing file: Exercise_u34.json\n",
      "Processing file: Exercise_u35.json\n",
      "Processing file: Exercise_u23.json\n",
      "Processing file: Exercise_u58.json\n",
      "Processing file: Exercise_u19.json\n",
      "Processing file: Exercise_u39.json\n",
      "Processing file: Exercise_u03.json\n",
      "Processing file: Exercise_u54.json\n",
      "Processing file: Exercise_u42.json\n",
      "Processing file: Exercise_u15.json\n"
     ]
    }
   ],
   "source": [
    "# List to collect all rows\n",
    "all_rows = []\n",
    "\n",
    "# Loop through all files in the Exercise folder\n",
    "for filename in os.listdir(folderExercise):\n",
    "    if filename.startswith(\"Exercise_u\") and filename.endswith(\".json\"):\n",
    "        user_id = filename.replace(\"Exercise_\", \"\").replace(\".json\", \"\")\n",
    "        file_path = os.path.join(folderExercise, filename)\n",
    "        print(f\"Processing file: {filename}\")\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            try:\n",
    "                entries = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "        for entry in entries:\n",
    "            # Parse values with fallbacks\n",
    "            exercise = entry.get(\"exercise\")\n",
    "            walk = entry.get(\"walk\")\n",
    "            have = entry.get(\"have\")\n",
    "            schedule = entry.get(\"schedule\")\n",
    "            location = entry.get(\"location\", None)\n",
    "            resp_time = entry.get(\"resp_time\", None)\n",
    "\n",
    "            # Convert timestamp to datetime\n",
    "            if resp_time:\n",
    "                dt = datetime.fromtimestamp(resp_time, tz=timezone.utc)\n",
    "\n",
    "                readable_time = dt.isoformat()\n",
    "                weekday = dt.strftime(\"%A\")\n",
    "                hour = dt.hour\n",
    "            else:\n",
    "                readable_time = None\n",
    "                weekday = None\n",
    "                hour = None\n",
    "\n",
    "            # Handle location\n",
    "            lat, lon = None, None\n",
    "            if location and location != \"Unknown\" and location != \"null\":\n",
    "                try:\n",
    "                    lat_str, lon_str = location.split(\",\")\n",
    "                    lat, lon = float(lat_str), float(lon_str)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            row = {\n",
    "                \"user_id\": user_id,\n",
    "                \"resp_time\": readable_time,\n",
    "                \"weekday\": weekday,\n",
    "                \"hour\": hour,\n",
    "                \"exercise\": int(exercise) if exercise and exercise != \"null\" else None,\n",
    "                \"walk\": int(walk) if walk and walk != \"null\" else None,\n",
    "                \"have\": int(have) if have and have != \"null\" else None,\n",
    "                \"schedule\": int(schedule) if schedule and schedule != \"null\" else None,\n",
    "                \"latitude\": lat,\n",
    "                \"longitude\": lon,\n",
    "                \"has_location\": int(location not in [\"Unknown\", \"null\", None]),\n",
    "            }\n",
    "\n",
    "            all_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'resp_time', 'weekday', 'hour', 'exercise', 'walk', 'have',\n",
      "       'schedule', 'latitude', 'longitude', 'has_location'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "df_exercise = pd.DataFrame(all_rows)\n",
    "df_exercise = df_exercise.sort_values(\n",
    "    by=[\"user_id\", \"resp_time\"]\n",
    ")  # sort by user + time\n",
    "print(df_exercise.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to 'CleanExerciseData.csv'\n",
      "Data saved to 'CleanExerciseData.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "print(\"Saving data to 'CleanExerciseData.csv'\")\n",
    "df_exercise.to_csv(\"CleanExerciseData.csv\", index=False)\n",
    "print(\"Data saved to 'CleanExerciseData.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing Social_u00.json to Social_u59.json\n",
    "folderExercise = \"./raw_data/EMA/response/Social/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store cleaned entries\n",
    "all_social_data = []\n",
    "\n",
    "# Loop through all relevant files\n",
    "for filename in os.listdir(folderExercise):\n",
    "    if filename.startswith(\"Social_u\") and filename.endswith(\".json\"):\n",
    "        user_id = filename.replace(\"Social_\", \"\").replace(\".json\", \"\")\n",
    "        file_path = os.path.join(folderExercise, filename)\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            try:\n",
    "                entries = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "        for entry in entries:\n",
    "            number = entry.get(\"number\")\n",
    "            location = entry.get(\"location\")\n",
    "            resp_time = entry.get(\"resp_time\")\n",
    "\n",
    "            # Convert timestamp to UTC datetime\n",
    "            try:\n",
    "                dt = datetime.fromtimestamp(resp_time, tz=timezone.utc)\n",
    "            except:\n",
    "                dt = None\n",
    "\n",
    "            all_social_data.append(\n",
    "                {\n",
    "                    \"user_id\": user_id,\n",
    "                    \"resp_time\": resp_time,\n",
    "                    \"datetime_utc\": dt,\n",
    "                    \"number\": number,\n",
    "                    \"location\": location,\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df_social = pd.DataFrame(all_social_data)\n",
    "df_social = df_social.sort_values(by=[\"user_id\", \"datetime_utc\"])  # sort by user + time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to 'CleanSocialData.csv'\n",
      "Data saved to 'CleanSocialData.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "print(\"Saving data to 'CleanSocialData.csv'\")\n",
    "df_social.to_csv(\"CleanSocialData.csv\", index=False)\n",
    "print(\"Data saved to 'CleanSocialData.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where Sleep_uXX.json files are located\n",
    "folderSleep = \"./raw_data/EMA/response/Sleep/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect cleaned records\n",
    "all_sleep_data = []\n",
    "\n",
    "# Go through all Sleep_uXX.json files\n",
    "for filename in os.listdir(folderSleep):\n",
    "    if filename.startswith(\"Sleep_u\") and filename.endswith(\".json\"):\n",
    "        user_id = filename.replace(\"Sleep_\", \"\").replace(\".json\", \"\")\n",
    "        file_path = os.path.join(folderSleep, filename)\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            try:\n",
    "                entries = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "        for entry in entries:\n",
    "            sleep_hours = entry.get(\"hour\")\n",
    "            sleep_quality = entry.get(\"rate\")\n",
    "            sleepiness = entry.get(\"social\")  # Trouble staying awake\n",
    "            location = entry.get(\"location\")\n",
    "            resp_time = entry.get(\"resp_time\")\n",
    "\n",
    "            # Convert timestamp to UTC datetime\n",
    "            try:\n",
    "                dt = datetime.fromtimestamp(resp_time, tz=timezone.utc)\n",
    "            except:\n",
    "                dt = None\n",
    "\n",
    "            all_sleep_data.append(\n",
    "                {\n",
    "                    \"user_id\": user_id,\n",
    "                    \"resp_time\": resp_time,\n",
    "                    \"datetime_utc\": dt,\n",
    "                    \"sleep_hours\": sleep_hours,\n",
    "                    \"sleep_quality\": sleep_quality,\n",
    "                    \"sleepiness\": sleepiness,\n",
    "                    \"location\": location,\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df_sleep = pd.DataFrame(all_sleep_data)\n",
    "df_sleep = df_sleep.sort_values(by=[\"user_id\", \"datetime_utc\"])  # sort by user + time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to 'CleanSleepData.csv'\n",
      "Data saved to 'CleanSleepData.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "print(\"Saving data to 'CleanSleepData.csv'\")\n",
    "df_sleep.to_csv(\"CleanSleepData.csv\", index=False)\n",
    "print(\"Data saved to 'CleanSleepData.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
